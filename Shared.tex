 % ----------------------- TODO ---------------------------

% Diese Daten müssen einmalig pro Vorlesung angepasst werden:
\newcommand{\COURSE}{Drag-Your-Motion Team Project}
\newcommand{\TUTOR}{Chuqiao Li}

% ----------------------- TODO ---------------------------

\documentclass[a4paper]{scrartcl}

\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{color}
\usepackage{graphicx}
\usepackage{lastpage}
\usepackage{listings}
\usepackage{tikz}
\usepackage{pdflscape}
\usepackage{subfigure}
\usepackage{float}
\usepackage{polynom}
\usepackage{hyperref}
\usepackage{tabularx}
\usepackage{forloop}
\usepackage{geometry}
\usepackage{listings}
\usepackage{fancybox}
\usepackage{tikz}
\usepackage{todonotes}

\input kvmacros

\setlength\parindent{0pt}


%Größe der Ränder setzen
\geometry{a4paper,left=3cm, right=3cm, top=3cm, bottom=3cm}

%Kopf- und Fußzeile
\pagestyle {fancy}
\fancyhead[L]{Tutor: \TUTOR}
\fancyhead[C]{\COURSE}
\fancyhead[R]{UI Group}

\fancyfoot[L]{}
\fancyfoot[C]{}
\fancyfoot[R]{Seite \thepage /\pageref*{LastPage}}

%Formatierung der Überschrift, hier nichts ändern
\def\header#1#2{
  \begin{center}
    {\Large Project Documentation}\\
    {Stefan Bochinger, 6347279}\\
    {Leonie Rämisch, 6504373}\\
    {Helene Pfahler, 6723015}\\
    {Joao Espirito Santo Azevedo, 6787574}
  \end{center}
}

\begin{document}
\header{Nr. \NUMBER}{\DEADLINE}

\section*{About this project}
The objective of this project was to use machine learning for drag-based editing of human animation. For this, we based our work on an interface called Aitviewer and a TCML cluster. 
In order to work efficiently, we split into two sub-teams: a front-end group focused on the user interface and a back-end group dedicated to model data processing.  

\section*{Our work}
% ----------------------- TODO ---------------------------
% Dokumentiert hier, welche Aufgaben ihr in diesem Projekt übernommen habt.

\subsection*{Stefan Bochinger}
\subsubsection*{Introduction}
In this section, I will summarize my contributions to the team project as the head of the UI group. My duties as such were, next to working on the code, planning the tasks for each week and directing in which way we would integrate certain features in the UI (e.g by testing and reviewing the code).

\subsubsection*{Setting up aitviewer}
The first 2 weeks, I worked on finding out how to set up aitviewer and using it with the SMPLH + AMASS body models which required many sudo packages to be installed and minor changes in the aitviewer code.\\
I also helped the others to set up aitviewer on their devices (which do not have access to a GPU). For that we had to change a line in the viewer.py file of the code to distinguish between devices that have cuda support (have cuda installed) and devices that don't. In the first few weeks that version was different between the members of the UI group, but we found a way to make it work and still all have the same version of the code.\\\\
In the end, we decided it would be beneficial to write a guide on how to set up aitviewer. I wrote one and it should cover all important steps and packages needed to make aitviewer successfully run (we sadly haven't gotten around to testing the guide out, since we all already made it work at that point).

\subsubsection*{Export for model group}
When we all could start working on the project, we started working on exporting files that the model group could work with. We started by adding the keyframes to the npz file and testing those files. For that, I wrote a simple script which loads those exported files (which ultimately became a prototype for the file loader by Joao).\\
In further weeks, we spent a lot of time creating a new method called export\_to\_AMASS() and altering it to fulfill the requirements of the model group and including our new features in the export. The method exports the files in aitviewer to files in AMASS format to give the model group all important information about the sequence. For each altering of the method, we also had to change the method loading amass files accordingly.\\\\
I spent a lot of time working on including the joints of the hands in the export which ultimately wasn't needed by the model group. In the end, I also decided to make the method flip the sequences to y\_up if they were set to z\_up.

\subsubsection*{Example inputs}
I, as the others in the UI group, created 2 example sequences for the model when we were done with the export function at the time. Sadly, these sequences aren't up to date anymore, we did some more work on the export method since. I also created some simpler example sequences in the end when I started experimenting on the model.

\subsubsection*{Keyframe Highlighting}
Together with Leonie, I worked on the highlighting of the keyframes (and resolving the bugs it caused in the beginning). At first the code for the highlighting wasn't in the smpl.py file itself, but in the end I found a way to refactor it so it is in the smpl.py file, making the code more cohesive and the feature easier to find in the code.

\subsubsection*{Prompt feature}
For the prompt feature, I added the JSON file with the prompts to the code base and made sure that it gets loaded and the prompts corresponding to the right AMASS file are given as a new attribute for SMPL sequences. I also added a prompt mode in the UI where you can see these prompts. The first one shown is open by default, the rest are retractable. The user can choose between only seeing prompts within the current time stamp or all prompts of the sequence. I also added buttons for deleting prompts and adding custom prompts, which Joao then implemented.

\subsubsection*{Work on the model}
As mentioned before, I flipped the sequences in the viewer itself, to make sure this is not the reason why the model wouldn't work. With this change, I created some simple example inputs and did a lot of experimenting on the model group's code. I changed the inpainting mask so the model would only generate the 10 frames before a key frame and the 10 frames after. Now the model was generating the right frames, but the motion was still spinning in the generated frames. The solution I ultimately found was to also set the inpainting mask to True for the first 5 features (rotation around the y axis, linear velocity on the xz plane and root height) which fixed the spinning and weird movement around the xz plane (because it just keeps those feature unchanged instead of generating). I also changed the feature mode of the inpainting mask to pos\_rot instead of pos\_rot\_vel (positions, rotations, velocities) because I found the generated motion to be way smoother that way. Maybe there could still be some experimenting on it with different transition lengths (how many frames get generated per keyframe) and different reconstruction weights to achieve a better output.\\\\
There are still some issues with the model, especially that it takes very long until the generation process is done and that there's a cutoff after 196 frames (if frame 190 is a keyframe, frame 180-189 get generated, but only 191-196 instead of 191-200). Both of those issues could maybe be solved by giving the model only the frames it should observe and generate in separate batches. Also keyframes currently only work in 10-frame-intervalls and prompts don't get used at all. However, to fix those issues, large parts of the code would have to be reworked, so I didn't work further on it.

\subsection*{Leonie Rämisch}
\subsubsection*{Introduction}
In the following, I will explain how I contributed to our team project "Motion Style Transfer with Drag-Based Editing". For the first half of our project, the Aitviewer group worked closely together and had many meetings throughout each week in which we worked together on the tasks. 

A small necessary step for the project was the setup of our GitHub project and the forking from the original AitViewer GitHub.

\subsubsection*{Method: export$\_$to$\_$AMASS}
Another big topic was the export\_to\_AMASS-Method, which is one of the main interfaces between the user who changes a sequence and the model which is supposed to alter the whole sequence depending on the user changes. This was a lot of work since we had to change the exported format multiple times, but in the end the model accepted the final format.

\subsubsection*{Keyframes}
The functionality of export\_to\_AMASS was extended by keyframes. If a frame is changed by a user, it will be marked as keyframe. The model uses this mark as a guide in order to adapt the whole sequence according to this specific or multiple keyframes.

\subsubsection*{Example Inputs}
Another necessary thing was the creation of the example inputs for the model. For this task, the Aitviewer group worked together and thought about different corner cases that need to be covered by an input. 

My corner cases were chosen within the Female Running folder. An input with many changed frames was created, as well as an input with 5 consecutive changed frames that each have a different body part changed. Both inputs are supposed to be a stress test of the model to see how it handles these specific changes.\\

From now on, we were able to split the work within the group much better since the key functionality that is needed for the project worked at this point. 

\subsubsection*{Colour of Mesh and Skeleton}
The goal was to make the change of the mesh and skeleton colour possible if a frame is marked as keyframe. I worked with Stefan on this task together.

We added a base colour, a light green, that will be applied on the mannequin if a frame is marked as keyframe. This led to the bug that the colour wheel within the UI couldn't be used anymore to change the colour of the untouched frames but this bug was fixed and now the colour can be changed as pleased again.

\subsubsection*{Prompts and their Export}
In the end, we brainstormed about possible prompt features and how we distribute them within the group. My task was to make sure that the prompts will be added to the exported sequence. This meant that the export\_to\_AMASS-Method needed to be changed again, but it works now just fine.  


\subsection*{Helene Pfahler}
I contributed to this project by working on various features of the user interface as well. In Aitviewer, our team successfully implemented the functionality to import AMASS files, which included the ability to save the edited files and effectively utilize text prompts to facilitate motion sequences.  
Additionally, I took the initiative to compose detailed reports for our weekly team meetings, which served to document our progress and outline the key points of discussion for the benefit of all team members.  

\subsubsection*{Setup of the UI}  
First, we set up the Aitviewer environment on our devices, which turned out to be a small challenge on its own. The Aitviewer tools by default require a GPU, which not all of our computers have, so we had to work our way around that issue. I contributed to the setup of the software by helping Joao with the rather complicated installation process.

\subsubsection*{export\_to\_AMASS method and keyframes}
For this project, we used the provided motion data in the AMASS format. Therefore, a necessary step was to code a method enabling us to save a motion in this format after editing it. The saved data also contained an array of keyframe indices, indicating which frames had been edited. As explained by Leonie, the requirements of the model to the specific format of the output data changed multiple times. This method was coded collectively within the UI sub-team.  

\subsubsection*{Example inputs}
I created example files, working as input for the model. For this, I used data in the 'Female Gestures' folder, which I edited to hit specific corner cases. One file contained only one keyframe in the middle of the motion. The second file had the very last frame be a keyframe. In my third file, two frames far apart from each other were edited. This data was then handed to the model sub-group.

\subsubsection*{View original motion}
To further enhance the user interface, I added a new feature. It contains a button enabling the user to view the original, unedited motion directly within the Aitviewer. To make this work, a new state variable to track if you're currently viewing the edited or the original motion was added. If this variable is true, the position and orientation of the joints are set back to their unedited state. This also required the original joints to be included in the exported (and imported) files, so if a motion is edited multiple times, the original motion remains the same throughout.

\subsection*{Joao Espirito Santo Azevedo}
\subsubsection*{Introduction}
In this Section I aim to report my contributions to this team project.\\

\subsubsection*{Personal difficulties}
For the first few weeks of this project I was involved in the model sub-group, participating in the setup of the cluster on which the AI runs.\\

I soon found this task to be somewhat outside my area of expertise and chose to switch over to the UI sub-group accordingly. Thankfully, this transition went smoothly since Jan simultaneously joined the model sub-group instead and the UI sub-group was very helpful in introducing me to the functioning of the Aitviewer programme.\\
\\
A further difficulty I had in the course of this project were two weeks where my laptop had technical problems with its fans and I was forced to try and relocate all my university work and such onto my older, significantly slower, Laptop.

\subsubsection*{Filename-Input Loader}
\subsubsection*{--Context}
In the beginning of this project, if we wanted to load a specific file with an animation onto the Aitviewer, we had to change the corresponding String in the `load\_AMASS.py`-file. After a few weeks in the UI sub-group, it became apparent that this was an annoying and inconvenient task/method.
\\
After some planning/brainstorming among us I assumed the task to handle the creation of a similar python-file (a loader, if you will), which allowed the user to specify which file should be loaded into the Aitviewer at the time of executing the file.

\subsubsection*{--how it works}
The file I worked on, `load\_export\_AMASS.py` relies heavily on the os-library of python.
To use this loader, it suffices to call the command `python load\_export\_AMASS.py` in the WSL/Linux Terminal while inside the `examples`-directory of the github repository.

\todo[color=grey!8, inline, bordercolor=white]{This command should work in any directory with a serving python-environment, though, so long as the `load\_export\_AMASS.py`-part of it is expanded with the corresponding relative path to it. (i.e. `../examples/load\_export\_AMASS.py`).}
\\
After a little while, the loader should present an indexed list of the contents within the `export`-folder of the local repository. At the same time, the loader should prompt the user to input a number specifying which of the files in this folder should be opened. Upon typing the number and pressing `Enter`, the loader should $"$do its magic$"$.

\subsubsection*{--Possible future problems}
If one were to encounter problems while working on this loader, these could be due to some paths not being relative or absolute; some missing/incorrect permissions of certain folders; incorrect formats of the files to open (this problem would probably not be fixable in the loader, but rather in the `SMPLSequence.py`-file) and/or problems with indexing/handling the list of directories.

\subsubsection*{Example Inputs}
As mentioned before, the UI sub-team worked together to create a couple animations to use as corner-case tests for the software.\\
The ones i created were all based on the `Female1 Walking` Animation. One of these focused on having multiple frames changed (ca. 15), spread evenly throughout the whole animation, the other had no changes and the last had changes applied to only the 10th first and the 10th last frames.

\subsubsection*{Prompts}
\subsubsection*{--Context}
Many of the animations we were given to open in the Aitviewer included prompts, which described the actions performed by the character as well as other information. Our task was to incorporate a way to view these in the Aitviewer.

\subsubsection*{--How it works}
The prompts are given as a multidimensional array. Every entry in its first dimension is a prompt of the animation. These, in turn, are also arrays.\\
To view these, we expanded the Aitviewer interface a bit further in the `SMPLSequence.py`-file by creating a respective interface therein. One can interact with it on the Aitviewer by going onto the `Editor`-window, clicking on the `AMASS Running`-dropdown menu and then on its `Prompts`-Button.\\
This interface allows the user to individually view only the current prompts as well as all prompts. Additionally, the user is welcome to add or delete prompts, and specify their timespans.

\subsubsection*{Usage of prompts}
Because our sub-group was right on schedule, we were even able to add text prompts to our motion files. These prompts can now be viewed, added, and deleted directly within the UI. My contribution to this was editing the export\_to\_AMASS method so the saved files also contained the text prompts associated with this motion.


\section*{Possible future additions}
Future improvements could include creating an automatic interface between the UI and the model to eliminate manual data transfer of the input/output of the model from/into the UI. The UI could also be modified to support the direct loading of exported sequences directly within Aitviewer, removing the need for terminal use. Another possible feature would include enabling the deletion of keyframes within the UI. Additionally, in the future, one could work on showing the exact changes that the model applied within the UI, making use of the "model indices", e.g. by also highlighting those frames in a different color. Lastly, to make full use of the model's capacities, a further exploration of the prompts on the model's side would be a possible future enhancement.

\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
